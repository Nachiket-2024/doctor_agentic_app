# ---------------------------- External Imports ----------------------------
# Import asynchronous HTTP client for making requests to the LLM server
import httpx  # Async HTTP client library

# ---------------------------- Internal Imports ----------------------------
# Import centralized settings containing LLM configuration
from ..core.settings import settings

# ---------------------------- LLM Client Class ----------------------------
# Define asynchronous client class for interacting with the LLM server
class LLMClient:
    """Asynchronous client for interacting with the Ollama LLM server."""

    # Initialize the LLM client with server URL, model, and settings
    def __init__(self):
        # Base URL of the LLM server (e.g., Ollama)
        self.base_url = settings.OLLAMA_BASE_URL

        # Model name to query (e.g., "llama3")
        self.model = settings.OLLAMA_MODEL

        # Sampling temperature controls randomness of LLM outputs
        self.temperature = settings.OLLAMA_TEMPERATURE

        # Async HTTP client instance for making reusable requests
        self.client = httpx.AsyncClient(base_url=self.base_url)

    # Async method to generate text from the LLM
    async def generate(self, prompt: str) -> str:
        """
        Send a prompt to the LLM and return the generated response.

        Args:
            prompt (str): Input text prompt for the LLM.

        Returns:
            str: Text generated by the LLM.
        """
        # Construct request payload for the Ollama API
        payload = {
            "model": self.model,         # Model to use for generation
            "prompt": prompt,            # Input prompt text
            "temperature": self.temperature  # Sampling temperature for randomness
        }

        # Send asynchronous POST request to the LLM server
        response = await self.client.post("/generate", json=payload)

        # Raise exception if response indicates HTTP error
        response.raise_for_status()

        # Extract JSON data from response
        data = response.json()

        # Return generated text, default to empty string if missing
        return data.get("text", "")
